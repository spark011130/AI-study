{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "\n",
    "Optimizers are used to fit the model weights in neural networks, using the loss function.\n",
    "In this notebook, we will go through every popular optimizers, from elaboration to codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Setup\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def data_generate():\n",
    "    # Generate synthetic data (for example, y = x**2 + 1)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    X = 2 * np.random.rand(100, 1)\n",
    "    X_b = np.column_stack((np.ones(100), X))\n",
    "    Y = 2 * X + 1 + np.random.randn(100, 1)\n",
    "    \n",
    "\n",
    "    # Initialize parameters (weights)\n",
    "    w = np.random.randn(2, 1)\n",
    "    \n",
    "    return X_b, Y, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ g(w) = \\frac{\\delta L(x,w)}{\\delta w} $$\n",
    "Where:\n",
    "\n",
    "$L(x,w)$: Loss\n",
    "\n",
    "If use Loss function for MSE:\n",
    "\n",
    "$$L(x,w) = \\frac{1}{m}\\sum^{m}_{i=1}(\\hat{y}_i - y_i)^2\n",
    "$$\n",
    "\n",
    "As we are using x to predict the line $y=2x+1$, we will calculate two weights: $w_0$ for y-intercept, $w_1$ for slope.\n",
    "\n",
    "which means that our $\\hat{y}$ can be converted into $w_0 + w_1 x$. Plugging the number, we can calculate the formula:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\n",
    "g(w) &= \\frac{\\delta L(x,w)}{\\delta w} \\\\\n",
    "&= \\frac{\\delta}{\\delta w}\\frac{1}{m}\\sum^{m}_{i=1}(\\hat{y}_i - y_i)^2 \\\\\n",
    "&= \\frac{\\delta}{\\delta w}\\frac{1}{m}\\sum^{m}_{i=1}(w_0 + w_1x - y_i)^2 \\\\\n",
    "&= \\frac{2}{m}\\sum^{m}_{i=1}(w_0 + w_1x_i - y_i)\\cdot (w_0 + w_1x_i - y_i)'\\\\\n",
    "g(w_0) &= \\frac{2}{m}\\sum^{m}_{i=1}(w_0 + w_1x_i - y_i)\\cdot 1\\\\\n",
    "g(w_1) &= \\frac{2}{m}\\sum^{m}_{i=1}(w_0 + w_1x_i - y_i)\\cdot x_i\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\vdots \\\\\n",
    "x_m\n",
    "\\end{bmatrix}, \\; X_b = \\begin{bmatrix}\n",
    "1 \\qquad x_1 \\\\\n",
    "1 \\qquad x_2 \\\\\n",
    "1 \\qquad x_3 \\\\\n",
    "\\vdots \\\\\n",
    "1 \\qquad x_m\n",
    "\\end{bmatrix}, Y = \\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "y_3 \\\\\n",
    "\\vdots \\\\\n",
    "y_m\n",
    "\\end{bmatrix}\\; W = \\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\n",
    "X_b^T \\cdot W = \\begin{bmatrix}\n",
    "w_0 + w_1x_1 = \\hat{y_1}\\\\\n",
    "w_0 + w_1x_2 = \\hat{y_2}\\\\\n",
    "\\vdots \\\\\n",
    "w_0 + w_1x_m = \\hat{y_m}\n",
    "\\end{bmatrix},\n",
    "\n",
    "\\frac{2}{m} \\cdot X_b^T \\cdot (X_b^T \\cdot W - Y) = \\begin{bmatrix}\n",
    "g(w_0) \\\\\n",
    "g(w_1)\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y, w):\n",
    "    m = len(X)\n",
    "    return 2 / m * X.T.dot((X.T - Y).dot(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ w_{t+1} = w_t - \\eta g(w_t) $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\eta$: learning rate\n",
    "\n",
    "$w_t$: t-th weight \n",
    "\n",
    "$g(w_t)$: Gradient of the loss function at weight $w_t$\n",
    "\n",
    "In gradient descent, the goal is to update the weights in a way that minimizes the loss. The direction of the update is determined by the gradient, which points in the direction of the steepest increase in the loss. The magnitude of the update is controlled by the learning rate, denoted as $\\eta$. Typically, the learning rate decreases over time in a process known as learning rate scheduling, where it starts at a higher value and gradually decreases to a lower value as training progresses.\n",
    "\n",
    "In each iteration of gradient descent, all input data points are used to compute the loss, and the weights are updated accordingly to minimize this loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSELoss(X, Y, w):\n",
    "    m = len(X)\n",
    "    return (1/m) * np.sum((X.dot(w)-Y) ** 2)\n",
    "\n",
    "def gradient_descent(X, Y, w, learning_rate = 0.1, max_iterations = 1000, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    \n",
    "    for t in range(1, max_iterations+1):\n",
    "        grad = gradient(X, Y, w)\n",
    "        w_new = w - learning_rate * grad \n",
    "        \n",
    "        if np.linalg.norm(w_new - w) < epsilon: # np.linalg.norm(): 벡터의 norm을 구하는 함수\n",
    "            print(f\"converged at iteration {t}.\")\n",
    "            break\n",
    "        w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stochastic Gradient Descent (SGD)\n",
    "\n",
    "$$ w_{t+1} = w_t - \\eta g(w_t) $$\n",
    "\n",
    "Same function with gradient descent, but the methodology of calculating the loss has been changed.\n",
    "\n",
    "The problem of the gradient descent is that calculating all x inputs in every iteration is computationally expensive, so picking a random set of the number (small batch, from one to many) and tune the data can make it more efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, Y, w, learning_rate = 0.01, max_iterations = 1000, batch_size = 1, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = len(X)\n",
    "    \n",
    "    for t in range(1, max_iterations+1):\n",
    "        shuffled_indices = np.random.permutation(m) # generates from 0 to m-1 randomly shuffled number array.\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        Y_shuffled = Y[shuffled_indices]\n",
    "        \n",
    "        for j in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[j:j+batch_size]\n",
    "            Y_batch = Y_shuffled[j:j+batch_size]\n",
    "            \n",
    "            grad = gradient(X_batch, Y_batch, w)\n",
    "            w_new = w - learning_rate * grad \n",
    "            \n",
    "            if np.linalg.norm(w_new - w) < epsilon: # np.linalg.norm(): 벡터의 norm을 구하는 함수\n",
    "                print(f\"converged at iteration {t}.\")\n",
    "                return w, loss_history\n",
    "            w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SGD with momentum\n",
    "\n",
    "$$ w_{t+1} = w_{t} + v_{t+1} \\\\\n",
    "v_{t+1} = \\rho v_{t} - \\eta g(w_t) \\\\\n",
    "w_{t+1} = w_{t} + \\rho v_{t+1}\n",
    "$$ \n",
    "\n",
    "$v$: velocity\n",
    "\n",
    "$\\rho$: momentum\n",
    "\n",
    "One of the problem in the SGD is that it is hard to say \"this weight is not the local minimum of loss, but it is the global minimum of loss\". Because using SGD, the weight is likely to get trapped into the local minimum solution of the loss. \n",
    "\n",
    "One solution for the problem is to add the velocity; the momentum to let weight learn from the previous move, and let it flow from the local minimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_with_momentum(X, Y, w, learning_rate = 0.01, momentum = 0.9, max_iterations = 1000, batch_size = 1, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = len(X)\n",
    "    v = 0\n",
    "    \n",
    "    for t in range(1, max_iterations+1):\n",
    "        shuffled_indices = np.random.permutation(m) # generates from 0 to m-1 randomly shuffled number array.\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        Y_shuffled = Y[shuffled_indices]\n",
    "        \n",
    "        for j in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[j:j+batch_size]\n",
    "            Y_batch = Y_shuffled[j:j+batch_size]\n",
    "            \n",
    "            grad = gradient(X_batch, Y_batch, w)\n",
    "            v_new = momentum * v - learning_rate * grad\n",
    "            w_new = w + v_new\n",
    "            \n",
    "            if np.linalg.norm(w_new - w) < epsilon: # np.linalg.norm(): 벡터의 norm을 구하는 함수\n",
    "                print(f\"converged at iteration {t}.\")\n",
    "                return w, loss_history\n",
    "            v = v_new\n",
    "            w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. SGD with Nesterov momentum\n",
    "\n",
    "$$ v_{t+1} = \\rho v_{t} - \\eta g(w_t + \\rho v_t) \\\\\n",
    "w_{t+1} = w_t + v_{t+1} $$\n",
    "\n",
    "SGD with momentum calculates the slope in the current location. It might cause the overshooting. So Nesterov momentum tries to solve the issue by calculating the slope in the next location, by calculating the next step's location. So it shoots the weight in more accurate direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_with_Nesterov_momentum(X, Y, w, learning_rate = 0.01, momentum = 0.9, max_iterations = 1000, batch_size = 1, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = len(X)\n",
    "    v = 0\n",
    "    \n",
    "    for t in range(1, max_iterations+1):\n",
    "        shuffled_indices = np.random.permutation(m) # generates from 0 to m-1 randomly shuffled number array.\n",
    "        X_shuffled = X[shuffled_indices]\n",
    "        Y_shuffled = Y[shuffled_indices]\n",
    "        \n",
    "        for j in range(0, m, batch_size):\n",
    "            X_batch = X_shuffled[j:j+batch_size]\n",
    "            Y_batch = Y_shuffled[j:j+batch_size]\n",
    "            \n",
    "            grad = gradient(X_batch, Y_batch, w + momentum * v)\n",
    "            v_new = momentum * v - learning_rate * grad\n",
    "            w_new = w + v_new\n",
    "            \n",
    "            if np.linalg.norm(w_new - w) < epsilon: # np.linalg.norm(): 벡터의 norm을 구하는 함수\n",
    "                print(f\"converged at iteration {t}.\")\n",
    "                return w, loss_history\n",
    "            v = v_new\n",
    "            w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. AdaGrad\n",
    "\n",
    "$$ \\omega_{i, t+1} = \\omega_{i, t} - \\frac{\\eta}{\\epsilon + \\sqrt{\\sum_{j=1}^{t}g(\\omega_{i,j})^2}}g(\\omega_{i ,t})$$\n",
    "\n",
    "$\\epsilon$: numerical stablizer to prevent zero division\n",
    "\n",
    "Schedules are most of the times expoenetially reduced and w gets closer to the target minimum (or local minimum, hopefully not). This is the problem with the decaying (reduced learning rate throughout the iteration) learning methods. It is decayed because it is assumed to get closer to the target, but it may not be, and even the learning rate may fizzled out even the hypothetical target value is far away.\n",
    "\n",
    "So AdaGrad applies learning rate separately in every parameters. More updated parameters get lower learning rate, and less updated parameters remain higher learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_grad(X, Y, w, learning_rate = 0.01, max_iterations = 1000, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = len(X)\n",
    "    G = 0 # G represents the total sum of the squared gradients\n",
    "    for t in range(1, max_iterations+1):\n",
    "        grad = gradient(X, Y, w)\n",
    "        G += grad ** 2\n",
    "        adjusted_learning_rate = w - learning_rate / (epsilon + np.sqrt(G))\n",
    "        w_new = w - adjusted_learning_rate * grad\n",
    "        if np.linalg.norm(w_new - w) < epsilon:\n",
    "            print(f\"converged at iteration {t}.\")\n",
    "            break\n",
    "        w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. RMSprop\n",
    "\n",
    "$$ v_{t+1} = \\beta v_t + (1-\\beta)g(w_t)^2 \\\\\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\epsilon + \\sqrt{v_{t+1}}}g(w_t) $$\n",
    "\n",
    "$\\beta$: discount parameter\n",
    "\n",
    "AdaGrad may decay faster than the target. Root mean squared propagation attempts to solve this problem by allowing the effective learning rate to both decrease and increase.\n",
    "\n",
    "The discount parameter determines how much of the previous v term is remembered.\n",
    "Small gradeient is scaled up, and the big gradient is encountered, it is scaled down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSprop(X, Y, w, learning_rate = 0.01, beta = 0.9, max_iterations = 1000, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = len(X)\n",
    "    v = 0\n",
    "    for t in range(1, max_iterations+1):\n",
    "        grad = gradient(X, Y, w)\n",
    "        v_new = beta*v + (1-beta) * grad**2\n",
    "        w_new = w - learning_rate / (epsilon + np.sqrt(v_new)) * grad\n",
    "        if np.linalg.norm(w_new - w) < epsilon:\n",
    "            print(f\"converged at iteration {t}.\")\n",
    "            break\n",
    "        v = v_new\n",
    "        w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Adaptive Moment Estimation (Adam)\n",
    "\n",
    "$$ m_{t+1} = \\beta_1 m_t + (1 - \\beta_1) g(w_t) \\\\\n",
    "v_{t+1} = \\beta_2 v_t + (1-\\beta_2) g(w_t)^2 \\\\\n",
    "w_{t+1} = w_t - \\frac{\\eta}{\\epsilon + \\sqrt{\\hat{v}_{t+1}}}\\hat{m}_{t+1} \\\\\n",
    "\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t} \\\\\n",
    "\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t} \\\\\n",
    "$$\n",
    "\n",
    "It utilizes the both benefits from Momentum, and RMS Prop.\n",
    "- Momentum: it adds up the inertia using the slopes.\n",
    "- RMSProp: it optimizes the learning rate using the slopes.\n",
    "\n",
    "Adam uses the two estimates from the two methods to tune the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam(X, Y, w, learning_rate = 0.01, beta1 = 0.9, beta2 = 0.99, max_iterations = 1000, epsilon = 1e-6):\n",
    "    loss_history = []\n",
    "    m = 0\n",
    "    v = 0\n",
    "    for t in range(1, max_iterations+1):\n",
    "        grad = gradient(X, Y, w)\n",
    "        m_new = beta1*m + (1-beta1) * grad\n",
    "        v_new = beta2*v + (1-beta2) * grad**2\n",
    "        m_hat_new = m_new / (1 - beta1)**t\n",
    "        v_hat_new = v_new / (1 - beta2)**t\n",
    "        \n",
    "        w_new = w - learning_rate / (epsilon + np.sqrt(v_hat_new)) * m_hat_new\n",
    "        \n",
    "        if np.linalg.norm(w_new - w) < epsilon:\n",
    "            print(f\"converged at iteration {t}.\")\n",
    "            break\n",
    "        \n",
    "        v = v_new\n",
    "        w = w_new\n",
    "        loss = MSELoss(X, Y, w)\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "    return w, loss_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
